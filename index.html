<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jaegeon Lee</title>

    <meta name="author" content="Jaegeon Lee">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Jaegeon Lee
                </p>
                <p>I am a senior staff research scientist at <a href="https://ai.google/research">Google Research</a> in <a href="https://en.wikipedia.org/wiki/One_Market_Plaza">San Francisco</a>, where I work on computer vision and machine learning.
                </p>
                <p>
                  At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
                </p>
                <p style="text-align:center">
                  <a href="mailto:lejae96@snu.ac.kr">Email</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/jonbarron/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
    
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:top">
              <div class="one">
                <img src='MGG/img/newfig1.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:top">
              <a href="https://reyllama.github.io/MGG">
                <papertitle>Analyzing Multimodal Objectives through the Lens of Generative Diffusion Guidance</papertitle>
              </a>
              <br>
              <strong>Chaerin Kong</strong>,
              <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
              <br>
              <em>ICLR</em> 2023 Workshop on Multimodal Representation Learning <em>(Spotlight)</em>
                <br>
                <a href="https://arxiv.org/abs/2302.10305">arXiv</a>
              /
              <a href="data/MGG_poster.png">poster</a>
                <p></p>
              <p>
              We study the semantic information encoded in widely used Vision-Language objectives (e.g., contrastive, captioning) by using each as diffusion guidance and inspecting the visualized images.
              </p>
            </td>
          </tr>
  
        </tbody></table>
				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Under Review</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='images/concat2.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://reyllama.github.io/concat">
                    <papertitle>ConcatPlexer: Additional Dim1 Batching for Faster ViTs</papertitle>
                  </a>
                  <br>
                  <a href="https://www.linkedin.com/in/dhk1349/">Donghoon Han</a>,
                  <a href="https://www.linkedin.com/in/shawn615/">Seunghyeun Seo</a>,
                  <a href="https://www.linkedin.com/in/jdh3577/">Donghyeon Jeon</a>,
                  <a href="https://www.linkedin.com/in/jiho-jang-58580b183/">Jiho Jang</a>,
                  <strong>Chaerin Kong</strong>,
                  <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
<!--                  <br>-->
<!--                  <a href="https://arxiv.org/abs/2207.14491">arXiv</a>-->
                  <p></p>
                  <p>
                  We explore means to accelerate ViT inference by concatenating abstract visual tokens of multiple images along dim=1 and processing them at once.
                  </p>
                </td>
              </tr>

          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='images/conpro.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://reyllama.github.io/conpro">
                    <papertitle>Conservative Generator, Progressive Discriminator: Coordination of Adversaries in Incremental Few-shot Image Synthesis</papertitle>
                  </a>
                  <br>
                  <strong>Chaerin Kong</strong>,
                  <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
                  <br>
                  <a href="https://arxiv.org/abs/2207.14491">arXiv</a>
                  <p></p>
                  <p>
                  We tackle the challenging task of few-shot incremental image synthesis by training a knowledge-preserving (conservative) generator and semantic learning (progressive) discriminator.
                  </p>
                </td>
              </tr>
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                The template is from <a href="https://jonbarron.info">Jon Barron</a>. Thank you for sharing!
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
